{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence sentiment  \\\n",
      "0   \\nArtificial intelligence is reshaping the world   LABEL_2   \n",
      "1   However, it may perpetuate stereotypes \\nand ...   LABEL_0   \n",
      "2   We must ensure responsible AI development for...   LABEL_2   \n",
      "\n",
      "   sentiment_score  similarity  This sentence promotes discrimination.  \\\n",
      "0         0.539701    0.259661                                0.000545   \n",
      "1         0.782136    0.530588                                0.616752   \n",
      "2         0.701031    0.146680                                0.024531   \n",
      "\n",
      "   This sentence is fair and unbiased.  This sentence is offensive.  \\\n",
      "0                             0.003537                     0.005358   \n",
      "1                             0.000087                     0.037541   \n",
      "2                             0.238128                     0.009524   \n",
      "\n",
      "                         final_hypothesis  \n",
      "0             This sentence is offensive.  \n",
      "1  This sentence promotes discrimination.  \n",
      "2     This sentence is fair and unbiased.  \n"
     ]
    }
   ],
   "source": [
    "from biascheck.analysis.docucheck import DocuCheck\n",
    "\n",
    "# Example text data\n",
    "text_data = \"\"\"\n",
    "Artificial intelligence is reshaping the world. However, it may perpetuate stereotypes \n",
    "and bias. We must ensure responsible AI development for a fair future.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize DocuCheck\n",
    "docucheck = DocuCheck(\n",
    "    data=text_data,\n",
    "    terms=[\"bias\", \"stereotypes\", \"discrimination\"],\n",
    "    use_advanced_sentiment=True,\n",
    "    use_contextual_analysis=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Analyze the document\n",
    "results_df = docucheck.analyze()\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>similarity</th>\n",
       "      <th>This sentence promotes discrimination.</th>\n",
       "      <th>This sentence is fair and unbiased.</th>\n",
       "      <th>This sentence is offensive.</th>\n",
       "      <th>final_hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nArtificial intelligence is reshaping the world</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.539701</td>\n",
       "      <td>0.259661</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>This sentence is offensive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, it may perpetuate stereotypes \\nand ...</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.782136</td>\n",
       "      <td>0.530588</td>\n",
       "      <td>0.616752</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.037541</td>\n",
       "      <td>This sentence promotes discrimination.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We must ensure responsible AI development for...</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.146680</td>\n",
       "      <td>0.024531</td>\n",
       "      <td>0.238128</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>This sentence is fair and unbiased.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  \\\n",
       "0   \\nArtificial intelligence is reshaping the world   LABEL_2   \n",
       "1   However, it may perpetuate stereotypes \\nand ...   LABEL_0   \n",
       "2   We must ensure responsible AI development for...   LABEL_2   \n",
       "\n",
       "   sentiment_score  similarity  This sentence promotes discrimination.  \\\n",
       "0         0.539701    0.259661                                0.000545   \n",
       "1         0.782136    0.530588                                0.616752   \n",
       "2         0.701031    0.146680                                0.024531   \n",
       "\n",
       "   This sentence is fair and unbiased.  This sentence is offensive.  \\\n",
       "0                             0.003537                     0.005358   \n",
       "1                             0.000087                     0.037541   \n",
       "2                             0.238128                     0.009524   \n",
       "\n",
       "                         final_hypothesis  \n",
       "0             This sentence is offensive.  \n",
       "1  This sentence promotes discrimination.  \n",
       "2     This sentence is fair and unbiased.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence sentiment  \\\n",
      "0  TYPE of BIAS DEFINITION EXAMPLE Contrast Bias:...   LABEL_0   \n",
      "1   They say all the right things, and their resu...   LABEL_1   \n",
      "2   Harshness Bias/Horn Effect: Occurs when the i...   LABEL_0   \n",
      "3   Other reasons this error may occur is that th...   LABEL_0   \n",
      "4   Leniency Bias: Occurs when the interviewer te...   LABEL_1   \n",
      "5   This can stem from various sources, such as i...   LABEL_0   \n",
      "6   Negative Emphasis Bias: Occurs when the inter...   LABEL_0   \n",
      "\n",
      "   sentiment_score similarity  This sentence promotes discrimination.  \\\n",
      "0         0.516592       None                                0.212012   \n",
      "1         0.433893       None                                0.009195   \n",
      "2         0.656869       None                                0.531591   \n",
      "3         0.835024       None                                0.020153   \n",
      "4         0.649333       None                                0.050318   \n",
      "5         0.590441       None                                0.021969   \n",
      "6         0.696444       None                                0.064062   \n",
      "\n",
      "   This sentence is fair and unbiased.  This sentence is offensive.  \\\n",
      "0                             0.000398                     0.024603   \n",
      "1                             0.000333                     0.012577   \n",
      "2                             0.000073                     0.019014   \n",
      "3                             0.000087                     0.011496   \n",
      "4                             0.000324                     0.003109   \n",
      "5                             0.000061                     0.017078   \n",
      "6                             0.000076                     0.003836   \n",
      "\n",
      "                         final_hypothesis  \n",
      "0  This sentence promotes discrimination.  \n",
      "1             This sentence is offensive.  \n",
      "2  This sentence promotes discrimination.  \n",
      "3  This sentence promotes discrimination.  \n",
      "4  This sentence promotes discrimination.  \n",
      "5  This sentence promotes discrimination.  \n",
      "6  This sentence promotes discrimination.  \n"
     ]
    }
   ],
   "source": [
    "from biascheck.analysis.docucheck import DocuCheck\n",
    "from biascheck.utils.terms_loader import load_document\n",
    "# Path to the PDF file\n",
    "pdf_path = load_document(\"/Users/balajis/Downloads/Bias.pdf\")\n",
    "\n",
    "# Initialize DocuCheck with a PDF document\n",
    "docucheck = DocuCheck(\n",
    "    document=pdf_path,\n",
    "    terms=None,\n",
    "    use_advanced_sentiment=True,\n",
    "    use_contextual_analysis=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Analyze the document\n",
    "results_df = docucheck.analyze()\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>similarity</th>\n",
       "      <th>This sentence promotes discrimination.</th>\n",
       "      <th>This sentence is fair and unbiased.</th>\n",
       "      <th>This sentence is offensive.</th>\n",
       "      <th>final_hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TYPE of BIAS DEFINITION EXAMPLE Contrast Bias:...</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.516592</td>\n",
       "      <td>None</td>\n",
       "      <td>0.212012</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.024603</td>\n",
       "      <td>This sentence promotes discrimination.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They say all the right things, and their resu...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.433893</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>This sentence is offensive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harshness Bias/Horn Effect: Occurs when the i...</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.656869</td>\n",
       "      <td>None</td>\n",
       "      <td>0.531591</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>This sentence promotes discrimination.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other reasons this error may occur is that th...</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.835024</td>\n",
       "      <td>None</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>This sentence promotes discrimination.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leniency Bias: Occurs when the interviewer te...</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.649333</td>\n",
       "      <td>None</td>\n",
       "      <td>0.050318</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>This sentence promotes discrimination.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This can stem from various sources, such as i...</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.590441</td>\n",
       "      <td>None</td>\n",
       "      <td>0.021969</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.017078</td>\n",
       "      <td>This sentence promotes discrimination.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative Emphasis Bias: Occurs when the inter...</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.696444</td>\n",
       "      <td>None</td>\n",
       "      <td>0.064062</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>This sentence promotes discrimination.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  \\\n",
       "0  TYPE of BIAS DEFINITION EXAMPLE Contrast Bias:...   LABEL_0   \n",
       "1   They say all the right things, and their resu...   LABEL_1   \n",
       "2   Harshness Bias/Horn Effect: Occurs when the i...   LABEL_0   \n",
       "3   Other reasons this error may occur is that th...   LABEL_0   \n",
       "4   Leniency Bias: Occurs when the interviewer te...   LABEL_1   \n",
       "5   This can stem from various sources, such as i...   LABEL_0   \n",
       "6   Negative Emphasis Bias: Occurs when the inter...   LABEL_0   \n",
       "\n",
       "   sentiment_score similarity  This sentence promotes discrimination.  \\\n",
       "0         0.516592       None                                0.212012   \n",
       "1         0.433893       None                                0.009195   \n",
       "2         0.656869       None                                0.531591   \n",
       "3         0.835024       None                                0.020153   \n",
       "4         0.649333       None                                0.050318   \n",
       "5         0.590441       None                                0.021969   \n",
       "6         0.696444       None                                0.064062   \n",
       "\n",
       "   This sentence is fair and unbiased.  This sentence is offensive.  \\\n",
       "0                             0.000398                     0.024603   \n",
       "1                             0.000333                     0.012577   \n",
       "2                             0.000073                     0.019014   \n",
       "3                             0.000087                     0.011496   \n",
       "4                             0.000324                     0.003109   \n",
       "5                             0.000061                     0.017078   \n",
       "6                             0.000076                     0.003836   \n",
       "\n",
       "                         final_hypothesis  \n",
       "0  This sentence promotes discrimination.  \n",
       "1             This sentence is offensive.  \n",
       "2  This sentence promotes discrimination.  \n",
       "3  This sentence promotes discrimination.  \n",
       "4  This sentence promotes discrimination.  \n",
       "5  This sentence promotes discrimination.  \n",
       "6  This sentence promotes discrimination.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zuse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
