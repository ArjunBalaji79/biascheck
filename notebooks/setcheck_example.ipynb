{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from biascheck.analysis.setcheck import SetCheck\n",
    "\n",
    "\n",
    "# Create a DataFrame \n",
    "df = pd.read_csv(\"/Users/balajis/Desktop/labeled_data.csv\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "set_check = SetCheck(\n",
    "    data=df,\n",
    "    input_cols=[\"tweet\"],\n",
    "    terms=None, #Optional Terms containing contextual terms, for example it can be discriminatory terms from a certain region\n",
    "    use_contextual_analysis=True,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Records: 5it [00:11,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence sentiment  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   LABEL_1   \n",
      "1  &amp; as a man you should always take the tras...   LABEL_1   \n",
      "2                   !!!!! RT @mleew17: boy dats cold   LABEL_0   \n",
      "3  tyga dwn bad for cuffin dat hoe in the 1st pla...   LABEL_0   \n",
      "4  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   LABEL_0   \n",
      "5  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   LABEL_0   \n",
      "6  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   LABEL_0   \n",
      "\n",
      "   sentiment_score  This sentence promotes discrimination.  \\\n",
      "0         0.563701                                0.994899   \n",
      "1         0.617583                                0.992610   \n",
      "2         0.462922                                0.975334   \n",
      "3         0.863422                                0.915440   \n",
      "4         0.949416                                0.917919   \n",
      "5         0.738627                                0.968459   \n",
      "6         0.856831                                0.863541   \n",
      "\n",
      "   This sentence is fair and unbiased.  This sentence is offensive.  \\\n",
      "0                             0.600710                     0.785676   \n",
      "1                             0.724538                     0.973056   \n",
      "2                             0.043419                     0.525954   \n",
      "3                             0.000861                     0.683379   \n",
      "4                             0.010111                     0.871527   \n",
      "5                             0.007297                     0.602092   \n",
      "6                             0.002288                     0.878864   \n",
      "\n",
      "  final_contextual_analysis  \n",
      "0            Discriminatory  \n",
      "1            Discriminatory  \n",
      "2            Discriminatory  \n",
      "3            Discriminatory  \n",
      "4            Discriminatory  \n",
      "5            Discriminatory  \n",
      "6            Discriminatory  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = set_check.analyze()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence sentiment  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   LABEL_1   \n",
      "1  &amp; as a man you should always take the tras...   LABEL_1   \n",
      "2                   !!!!! RT @mleew17: boy dats cold   LABEL_0   \n",
      "3  tyga dwn bad for cuffin dat hoe in the 1st pla...   LABEL_0   \n",
      "4  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   LABEL_0   \n",
      "5  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   LABEL_0   \n",
      "6  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   LABEL_0   \n",
      "\n",
      "   sentiment_score  This sentence promotes discrimination.  \\\n",
      "0         0.563701                                0.994899   \n",
      "1         0.617583                                0.992610   \n",
      "2         0.462922                                0.975334   \n",
      "3         0.863422                                0.915440   \n",
      "4         0.949416                                0.917919   \n",
      "5         0.738627                                0.968459   \n",
      "6         0.856831                                0.863541   \n",
      "\n",
      "   This sentence is fair and unbiased.  This sentence is offensive.  \\\n",
      "0                             0.600710                     0.785676   \n",
      "1                             0.724538                     0.973056   \n",
      "2                             0.043419                     0.525954   \n",
      "3                             0.000861                     0.683379   \n",
      "4                             0.010111                     0.871527   \n",
      "5                             0.007297                     0.602092   \n",
      "6                             0.002288                     0.878864   \n",
      "\n",
      "  final_contextual_analysis  \n",
      "0            Discriminatory  \n",
      "1            Discriminatory  \n",
      "2            Discriminatory  \n",
      "3            Discriminatory  \n",
      "4            Discriminatory  \n",
      "5            Discriminatory  \n",
      "6            Discriminatory  \n"
     ]
    }
   ],
   "source": [
    "# Filter results for \"Discriminatory\" sentences\n",
    "filtered_df = set_check.filter_dataframe({\"final_contextual_analysis\": \"Discriminatory\"})\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
